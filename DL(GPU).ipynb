{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec56339",
   "metadata": {},
   "source": [
    "# 1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46631608",
   "metadata": {},
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1c1098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df8ed49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a24ef79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d377c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cc8e0cb",
   "metadata": {
    "id": "3cc8e0cb"
   },
   "source": [
    "# 2. Data Acquisition\n",
    " \n",
    "For the problem identified by you, students have to find the data source themselves from any data source.\n",
    "\n",
    "## 2.1 Code for converting the above downloaded data into a form suitable for DL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b51d895",
   "metadata": {
    "id": "4b51d895"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "812edb18",
   "metadata": {
    "id": "812edb18"
   },
   "source": [
    "## 2.1 Write your observations from the above. \n",
    "\n",
    "1. Size of the dataset\n",
    "2. What type of data attributes are there?\n",
    "3. What are you classifying?\n",
    "4. Plot the distribution of the categories of the target / label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60d80d2f",
   "metadata": {
    "id": "60d80d2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size:  (50000, 32, 32, 3)\n",
      "Test dataset size:  (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#--------------Type the  below this line--------------\n",
    "################################################################\n",
    "# 2.1.1.: Size of the dataset\n",
    "################################################################\n",
    "print(\"Training dataset size: \", x_train.shape)\n",
    "print(\"Test dataset size: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c86385d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datatype of the training dataset is <class 'numpy.ndarray'>\n",
      "The unique target values are [0 1 2 3 4 5 6 7 8 9]\n",
      "The unique training values are [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255]\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# 2.1.2.: What type of data attributes are there?\n",
    "################################################################\n",
    "print(\"The datatype of the training dataset is\", type(x_train))\n",
    "print(\"The unique target values are\", np.unique(y_train))\n",
    "print(\"The unique training values are\", np.unique(x_train))\n",
    "################################################################################################################################\n",
    "# From the output of the above statements, it's clear that we are dealing with numerical data attributes.\n",
    "#   - the input numerical values images of size 32x32 pixels with 3 color channels\n",
    "#   - the target numerical values represent the following labels\n",
    "#       Label\tDescription\n",
    "#       0\tairplane\n",
    "#       1\tautomobile\n",
    "#       2\tbird\n",
    "#       3\tcat\n",
    "#       4\tdeer\n",
    "#       5\tdog\n",
    "#       6\tfrog\n",
    "#       7\thorse\n",
    "#       8\tship\n",
    "#       9\ttruck\n",
    "# Source: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10/load_data\n",
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "397a8311",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# 2.1.3. What are you classifying?\n",
    "# We are classifying small color images of size 32x32, labeled over 10 categories.\n",
    "# Source: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10/load_data\n",
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b57584ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################################################################################################################################\n",
    "# 2.1.4. Plot the distribution of the categories of the target / label. \n",
    "################################################################################################################################\n",
    "# Get the unique categories\n",
    "categories = np.unique(y_train)\n",
    "\n",
    "# Count the number of images in each category\n",
    "counts = np.zeros(len(categories))\n",
    "for i in y_train:\n",
    "    counts[i[0]] += 1\n",
    "\n",
    "# Plot the distribution of the categories\n",
    "plt.bar(categories, counts)\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Categories in CIFAR10 Dataset')\n",
    "plt.show()\n",
    "################################################################################################################################\n",
    "# The plot below shows that the training dataset is balanced across categories... having 5000 images in each category.\n",
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e0e36",
   "metadata": {
    "id": "102e0e36"
   },
   "source": [
    "# 3. Data Preparation -- Score: 1 Mark\n",
    "\n",
    "Perform the data prepracessing that is required for the data that you have downloaded. \n",
    "\n",
    "\n",
    "This stage depends on the dataset that is used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fdebf8",
   "metadata": {
    "id": "06fdebf8"
   },
   "source": [
    "## 3.1 Apply pre-processing techiniques\n",
    "\n",
    "* to remove duplicate data\n",
    "* to impute or remove missing data\n",
    "* to remove data inconsistencies\n",
    "* Encode categorical data\n",
    "* Normalize the data\n",
    "* Feature Engineering\n",
    "* Stop word removal, lemmatiation, stemming, vectorization\n",
    "\n",
    "\n",
    "IF ANY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c34a47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "################################################################################################################################\n",
    "# [Normalize the input data:]\n",
    "# We'll normalize the input images pixels' color value from the range (0, 255) to the range (0, 1).\n",
    "################################################################################################################################\n",
    "x_train = x_train/np.ptp(x_train)\n",
    "x_test = x_test/np.ptp(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd3118eb",
   "metadata": {
    "id": "dd3118eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################\n",
    "# [Feature Engineering:]\n",
    "# We'll flatten the target variables from 1x1 arrays into a flat list for easier correspondence with input images.\n",
    "################################################################################################################################\n",
    "y_train, y_test = (y_train.reshape(-1,), y_test.reshape(-1,))   #-1 ensures that first dimension is kept as it is; blank 2nd dimension ensures that the other dimensions are flattened.\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793cd04b",
   "metadata": {
    "id": "793cd04b"
   },
   "source": [
    "## 3.2 Identify the target variables.\n",
    "\n",
    "* Separate the data front the target such that the dataset is in the form of (X,y) or (Features, Label)\n",
    "\n",
    "* Discretize / Encode the target variable or perform one-hot encoding on the target or any other as and if required.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9089b57",
   "metadata": {
    "id": "c9089b57"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "################################################################################################################################\n",
    "# Tensorflow's load_data() function separates the dataset in the form (X,y) on its own. Hence, this step isn't required.\n",
    "################################################################################################################################\n",
    "\n",
    "# one-hot encoded encoding on the target:\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10, dtype='float32')\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e0c299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class_labels = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck',]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd14601",
   "metadata": {},
   "source": [
    "## 3.3 Split the data into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a74cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "################################################################################################\n",
    "# Tensorflow's load_data() function does this splitting implicitly for us.\n",
    "# As shown in section 2.1.1., \n",
    "#   - the training set consists of 50000 training samples;\n",
    "#   - the test set consists of 10000 training samples.\n",
    "################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cec4fc",
   "metadata": {
    "id": "e3cec4fc"
   },
   "source": [
    "## 3.4 Preprocessing report\n",
    "\n",
    "Mention the method adopted  and justify why the method was used\n",
    "* to remove duplicate data, if present \n",
    "* to impute or remove missing data, if present \n",
    "* to remove data inconsistencies, if present \n",
    "* to encode categorical data \n",
    "* the normalization technique used\n",
    "\n",
    "If the any of the above are not present, then also add in the report below.\n",
    "\n",
    "Report the size of the training dataset and testing dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71c77697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size:  (50000, 32, 32, 3)\n",
      "Test dataset size:  (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "##---------Type the answer below this line------------------##\n",
    "#################################################################################################################################\n",
    "# Ours is a very healthy dataset. It doesn't require any of these preprocessing steps.\n",
    "# Also, instead of being a data-oriented dataset, ours is an image-based dataset. \n",
    "#       - Hence, also, doesn't require any of these preprocessing steps.\n",
    "# We've already one-hot encocded the target values in section 3.2. above; hence, that's not required here either.\n",
    "#################################################################################################################################\n",
    "print(\"Training dataset size: \", x_train.shape)\n",
    "print(\"Test dataset size: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae0b5d2",
   "metadata": {
    "id": "3ae0b5d2"
   },
   "source": [
    "# 4. Deep Neural Network Architecture - Score:  Marks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186bf4d7",
   "metadata": {
    "id": "186bf4d7"
   },
   "source": [
    "## 4.1 Design the architecture that you will be using\n",
    "\n",
    "* Sequential Model Building with Activation for each layer.\n",
    "* Add dense layers, specifying the number of units in each layer and the activation function used in the layer.\n",
    "* Use Relu Activation function in each hidden layer\n",
    "* Use Sigmoid / softmax Activation function in the output layer as required\n",
    "\n",
    "DO NOT USE CNN OR RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "868d7b27",
   "metadata": {
    "id": "868d7b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "regularizer = keras.regularizers.L2()\n",
    "model_5layers = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (32,32,3)),\n",
    "    # keras.layers.Dense(3000, activation = \"relu\"),  # hidden layer#1 with 3000 units (because previous flattened layer is supplying 32x32x3 = 3072 elements)\n",
    "    keras.layers.Dense(1536, activation = \"relu\", kernel_regularizer=regularizer, bias_regularizer=regularizer),  # hidden layer#1 with 1536 units (complete guesswork here as to why we've choses 1536 nodes)\n",
    "    keras.layers.Dense(768, activation = \"relu\", kernel_regularizer=regularizer, bias_regularizer=regularizer),  # hidden layer#2 with 768 units (complete guesswork here as to why we've choses 768 nodes)\n",
    "    keras.layers.Dense(384, activation = \"relu\", kernel_regularizer=regularizer, bias_regularizer=regularizer),  # hidden layer#3 with 384 units (complete guesswork here as to why we've choses 384 nodes)\n",
    "    # keras.layers.Dense(192, activation = \"relu\"),  # hidden layer#2 with 1000 units (complete guesswork here as to why we've choses 1000 nodes)\n",
    "    # keras.layers.Dense(96, activation = \"relu\"),  # hidden layer#2 with 1000 units (complete guesswork here as to why we've choses 1000 nodes)\n",
    "    # keras.layers.Dense(48, activation = \"relu\"),  # hidden layer#2 with 1000 units (complete guesswork here as to why we've choses 1000 nodes)\n",
    "    # keras.layers.Dense(24, activation = \"relu\"),  # hidden layer#2 with 1000 units (complete guesswork here as to why we've choses 1000 nodes)\n",
    "    keras.layers.Dense(10, activation='sigmoid'),   # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575f9e37",
   "metadata": {
    "id": "575f9e37"
   },
   "source": [
    "## 4.2 DNN Report\n",
    "\n",
    "Report the following and provide justification for the same.\n",
    "\n",
    "\n",
    "\n",
    "* Number of layers\n",
    "* Number of units in each layer\n",
    "* Total number of trainable parameters \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ad56d90",
   "metadata": {
    "id": "4d614311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers =  5\n",
      "Number of units in layer # 1 = 3072\n",
      "Number of units in layer # 2 = 1536\n",
      "Number of units in layer # 3 = 768\n",
      "Number of units in layer # 4 = 384\n",
      "Number of units in layer # 5 = 10\n",
      "Total number of trainable parameters =  6199690\n"
     ]
    }
   ],
   "source": [
    "##---------Type the answer below this line------------------##\n",
    "print(\"Number of layers = \", len(model_5layers.layers))\n",
    "for i in range(len(model_5layers.layers)):\n",
    "    print(\"Number of units in layer #\", (i+1), \"=\", model_5layers.layers[i].output_shape[1])\n",
    "print(\"Total number of trainable parameters = \", model_5layers.count_params())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdbc82a1",
   "metadata": {
    "id": "bdbc82a1"
   },
   "source": [
    "# 5. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca214eb3",
   "metadata": {
    "id": "ca214eb3"
   },
   "source": [
    "## 5.1 Configure the training\n",
    "\n",
    "Configure  the model for training, by using appropriate optimizers and regularizations\n",
    "\n",
    "Compile with categorical CE loss and metric accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a85e9754",
   "metadata": {
    "id": "a85e9754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "model_5layers.compile(\n",
    "    optimizer=keras.optimizers.experimental.SGD(momentum=0.01),    # Gradient descent (with momentum) optimizer, as mandated in section 5.2.\n",
    "    loss=keras.losses.CategoricalCrossentropy(),    # Categorical CE loss, as mandated above (also required because our target label is one-hot encoded).\n",
    "    metrics=[\n",
    "        keras.metrics.Accuracy(),\n",
    "        keras.metrics.Precision(),\n",
    "        keras.metrics.Recall(),\n",
    "        ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fd60d8",
   "metadata": {},
   "source": [
    "## 5.2 Train the model\n",
    "\n",
    "Train Model with cross validation, with total time taken shown for 20 epochs.\n",
    "\n",
    "Use SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8efaa227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionsDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionsDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AnonymousIteratorV3 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Epoch 1/20\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_1166 in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_6' defined at (most recent call last):\n    File \"C:\\Program Files\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Program Files\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_2248\\2710308037.py\", line 3, in <module>\n      history_5layers_model = model_5layers.fit(x_train,y_train, epochs=20, validation_split=(1/20))\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 481, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 940, in apply_gradients\n      super().apply_gradients(grads_and_vars)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 526, in apply_gradients\n      self._internal_apply_gradients(grads_and_vars)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 943, in _internal_apply_gradients\n      tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 993, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 988, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_6'\nCould not find compiler for platform DML: NOT_FOUND: could not find registered compiler for platform DML -- was support for that platform linked in?\n\t [[{{node StatefulPartitionedCall_6}}]] [Op:__inference_train_function_1166]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m##---------Type the code below this line------------------##\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39m/GPU:0\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     history_5layers_model \u001b[39m=\u001b[39m model_5layers\u001b[39m.\u001b[39;49mfit(x_train,y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m20\u001b[39;49m))\n",
      "File \u001b[1;32md:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_6' defined at (most recent call last):\n    File \"C:\\Program Files\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Program Files\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_2248\\2710308037.py\", line 3, in <module>\n      history_5layers_model = model_5layers.fit(x_train,y_train, epochs=20, validation_split=(1/20))\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 481, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 940, in apply_gradients\n      super().apply_gradients(grads_and_vars)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 526, in apply_gradients\n      self._internal_apply_gradients(grads_and_vars)\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 943, in _internal_apply_gradients\n      tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 993, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"d:\\Tutorials\\Python\\TensorFlow\\tfdml_plugin\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 988, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_6'\nCould not find compiler for platform DML: NOT_FOUND: could not find registered compiler for platform DML -- was support for that platform linked in?\n\t [[{{node StatefulPartitionedCall_6}}]] [Op:__inference_train_function_1166]"
     ]
    }
   ],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "with tf.device('/GPU:0'):\n",
    "    history_5layers_model = model_5layers.fit(x_train,y_train, epochs=20, validation_split=(1/20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd0c56",
   "metadata": {},
   "source": [
    "Justify your choice of optimizers and regulizations used and the hyperparameters tuned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d2981",
   "metadata": {},
   "outputs": [],
   "source": [
    "##---------Type the  below this line------------------##\n",
    "################################################################################################################################\n",
    "# - SGD Optimier is a relatively simple optimizer to implement and understand.\n",
    "# - L2 regularization is a simple regularization, which helps to prevent overfitting.\n",
    "# - Hyperparameters tune:\n",
    "#       - No. of layers: A 5 layer neural network is a good starting point for a small dataset like CIFAR10. \n",
    "#       - Number of neurons per layer: We have chosen 1536, 768, 384, and 10 neurons per layer, respectively. This is a reasonable number of neurons for each layer. A larger number of neurons could potentially improve accuracy, but it would also increase the risk of overfitting.\n",
    "#       - Learning rate: Used the default SGD optimizer learning rate (0.001), which is a small value to prevent the model from oscillating during training.\n",
    "#       - Momentum: A momentum of 0.01 is small \n",
    "#       - Accuracy metric: Being a balanced data, accuracy is a good metric for model evaluation to train a model on the CIFAR10 dataset.\n",
    "################################################################################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06f1173c",
   "metadata": {
    "id": "06f1173c"
   },
   "source": [
    "# 6. Test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7042235d",
   "metadata": {
    "id": "7042235d"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "lossAndMetrics_5layers_model = model_5layers.evaluate(x_test, y_test,return_dict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb57940c",
   "metadata": {
    "id": "eb57940c"
   },
   "source": [
    "# 7. Intermediate result\n",
    "\n",
    "1. Plot the training and validation accuracy history.\n",
    "2. Plot the training and validation loss history. \n",
    "3. Report the testing accuracy and loss.\n",
    "4. Show Confusion Matrix for testing dataset.\n",
    "5. Report values for preformance study metrics like accuracy, precision, recall, F1 Score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a03506",
   "metadata": {},
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "# 7.1. Plot the training and validation accuracy history\n",
    "plt.plot(history_5layers_model.history['accuracy'])\n",
    "plt.plot(history_5layers_model.history['val_accuracy'])\n",
    "plt.title('Training and Validation Accuracy History')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f173fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2. Plot the training and validation loss history\n",
    "plt.plot(history_5layers_model.history['loss'])\n",
    "plt.plot(history_5layers_model.history['val_loss'])\n",
    "plt.title('Training and Validation Loss History')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8707503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3. Report the testing accuracy and loss.\n",
    "lossAndMetrics_5layers_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8908368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.4. Show Confusion Matrix for testing dataset.\n",
    "actualLabels = tf.math.argmax(y_test, axis=1)\n",
    "predictedLabels = tf.math.argmax(input=model_5layers.predict(x_test), axis=1)\n",
    "tf.math.confusion_matrix(\n",
    "    labels=actualLabels,\n",
    "    predictions=predictedLabels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# 7.5. Report values for preformance study metrics like accuracy, precision, recall, F1 Score.\n",
    "#       - This task is already accomplished in step 7.3. above.\n",
    "################################################################################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8146c5b",
   "metadata": {},
   "source": [
    "# 8. Model architecture\n",
    "\n",
    "\n",
    "Modify the architecture designed in section 4.1 \n",
    "\n",
    "1. by decreasing one layer\n",
    "2. by increasing one layer\n",
    "\n",
    "For example, if the architecture in 4.1 has 5 layers, then 8.1 should have 4 layers and 8.2 should have 6 layers.\n",
    "\n",
    "Plot the comparison of the training and validation accuracy of the three architecures (4.1, 8.1 and 8.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15e18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "model_4layers = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (32,32,3)),\n",
    "    keras.layers.Dense(1536, activation = \"relu\", kernel_regularizer=regularizer, bias_regularizer=regularizer),  # hidden layer#1 with 1536 units (complete guesswork here as to why we've choses 1536 nodes)\n",
    "    keras.layers.Dense(768, activation = \"relu\", kernel_regularizer=regularizer, bias_regularizer=regularizer),  # hidden layer#2 with 768 units (complete guesswork here as to why we've choses 768 nodes)\n",
    "    keras.layers.Dense(10, activation='sigmoid'),   # output layer\n",
    "])\n",
    "model_6layers = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (32,32,3)),\n",
    "    keras.layers.Dense(1536, activation = \"relu\", kernel_regularizer=regularizer, bias_regularizer=regularizer),  # hidden layer#1 with 1536 units (complete guesswork here as to why we've choses 1536 nodes)\n",
    "    keras.layers.Dense(768, activation = \"relu\", kernel_regularizer=regularizer, bias_regularizer=regularizer),  # hidden layer#2 with 768 units (complete guesswork here as to why we've choses 768 nodes)\n",
    "    keras.layers.Dense(384, activation = \"relu\", kernel_regularizer=regularizer, bias_regularizer=regularizer),  # hidden layer#3 with 384 units (complete guesswork here as to why we've choses 384 nodes)\n",
    "    keras.layers.Dense(192, activation = \"relu\"),  # hidden layer#2 with 1000 units (complete guesswork here as to why we've choses 1000 nodes)\n",
    "    keras.layers.Dense(10, activation='sigmoid'),   # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a4ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4layers.compile(\n",
    "    optimizer=keras.optimizers.experimental.SGD(momentum=0.01),    # Gradient descent (with momentum) optimizer, as mandated in section 5.2.\n",
    "    loss=keras.losses.CategoricalCrossentropy(),    # Categorical CE loss, as mandated above (also required because our target label is one-hot encoded).\n",
    "    metrics=[\n",
    "        keras.metrics.Accuracy(),\n",
    "        keras.metrics.Precision(),\n",
    "        keras.metrics.Recall(),\n",
    "        ],\n",
    ")\n",
    "model_6layers.compile(\n",
    "    optimizer=keras.optimizers.experimental.SGD(momentum=0.01),    # Gradient descent (with momentum) optimizer, as mandated in section 5.2.\n",
    "    loss=keras.losses.CategoricalCrossentropy(),    # Categorical CE loss, as mandated above (also required because our target label is one-hot encoded).\n",
    "    metrics=[\n",
    "        keras.metrics.Accuracy(),\n",
    "        keras.metrics.Precision(),\n",
    "        keras.metrics.Recall(),\n",
    "        ],\n",
    ")\n",
    "history_4layers_model = model_4layers.fit(x_train,y_train, epochs=20, validation_split=(1/20))\n",
    "history_6layers_model = model_6layers.fit(x_train,y_train, epochs=20, validation_split=(1/20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37ec0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################################\n",
    "# Comparison of the training and validation accuracy of the three architecures (4.1, 8.1 and 8.2)\n",
    "################################################################################################################################################\n",
    "plt.plot(history_4layers_model.history['accuracy'])\n",
    "plt.plot(history_4layers_model.history['val_accuracy'])\n",
    "plt.plot(history_5layers_model.history['accuracy'])\n",
    "plt.plot(history_5layers_model.history['val_accuracy'])\n",
    "plt.plot(history_6layers_model.history['accuracy'])\n",
    "plt.plot(history_6layers_model.history['val_accuracy'])\n",
    "plt.title('Training and Validation Accuracy History')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend([\n",
    "    '4-Layers Training Accuracy', '4-Layers Validation Accuracy', \n",
    "    '5-Layers Training Accuracy', '5-Layers Validation Accuracy', \n",
    "    '6-Layers Training Accuracy', '6-Layers Validation Accuracy', \n",
    "    ], \n",
    "    loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8d38cb0",
   "metadata": {},
   "source": [
    "# 9. Regularisations\n",
    "\n",
    "Modify the architecture designed in section 4.1\n",
    "\n",
    "1. Dropout of ratio 0.25\n",
    "2. Dropout of ratio 0.25 with L2 regulariser with factor 1e−04. \n",
    "\n",
    "Plot the comparison of the training and validation accuracy of the three (4.1, 9.1 and 9.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7497b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "################################################################\n",
    "# 9.1. 5-layered model with dropout, without regularization.\n",
    "################################################################\n",
    "model_5layers_withDropout_WithoutRegularization = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (32,32,3)),\n",
    "    keras.layers.Dense(1536, activation = \"relu\", ),  # hidden layer#1 with 1536 units (complete guesswork here as to why we've choses 1536 nodes)\n",
    "    keras.layers.Dropout(rate=0.25),                 # Dropout layer of ratio 0.25.\n",
    "    keras.layers.Dense(768, activation = \"relu\",),  # hidden layer#2 with 768 units (complete guesswork here as to why we've choses 768 nodes)\n",
    "    keras.layers.Dropout(rate=0.25),                 # Dropout layer of ratio 0.25.\n",
    "    keras.layers.Dense(384, activation = \"relu\",),  # hidden layer#3 with 384 units (complete guesswork here as to why we've choses 384 nodes)\n",
    "    keras.layers.Dropout(rate=0.25),                 # Dropout layer of ratio 0.25.\n",
    "    keras.layers.Dense(10, activation='sigmoid'),   # output layer\n",
    "])\n",
    "################################################################################################################################\n",
    "# 9.2. 5-layered model with dropout, with L2 regularization with factor 1e-04.\n",
    "################################################################################################################################\n",
    "regularizer2 = keras.regularizers.L2(l2 = 1e-04)\n",
    "model_5layers_withDropout_WithRegularization = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (32,32,3)),\n",
    "    keras.layers.Dense(1536, activation = \"relu\", ),  # hidden layer#1 with 1536 units (complete guesswork here as to why we've choses 1536 nodes)\n",
    "    keras.layers.Dropout(rate=0.25),                 # Dropout layer of ratio 0.25.\n",
    "    keras.layers.Dense(768, activation = \"relu\",),  # hidden layer#2 with 768 units (complete guesswork here as to why we've choses 768 nodes)\n",
    "    keras.layers.Dropout(rate=0.25),                 # Dropout layer of ratio 0.25.\n",
    "    keras.layers.Dense(384, activation = \"relu\",),  # hidden layer#3 with 384 units (complete guesswork here as to why we've choses 384 nodes)\n",
    "    keras.layers.Dropout(rate=0.25),                 # Dropout layer of ratio 0.25.\n",
    "    keras.layers.Dense(10, activation='sigmoid'),   # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5layers_withDropout_WithoutRegularization.compile(\n",
    "    optimizer=keras.optimizers.experimental.SGD(momentum=0.01),    # Gradient descent (with momentum) optimizer, as mandated in section 5.2.\n",
    "    loss=keras.losses.CategoricalCrossentropy(),    # Categorical CE loss, as mandated above (also required because our target label is one-hot encoded).\n",
    "    metrics=[\n",
    "        keras.metrics.Accuracy(),\n",
    "        keras.metrics.Precision(),\n",
    "        keras.metrics.Recall(),\n",
    "        ],\n",
    ")\n",
    "model_5layers_withDropout_WithRegularization.compile(\n",
    "    optimizer=keras.optimizers.experimental.SGD(momentum=0.01),    # Gradient descent (with momentum) optimizer, as mandated in section 5.2.\n",
    "    loss=keras.losses.CategoricalCrossentropy(),    # Categorical CE loss, as mandated above (also required because our target label is one-hot encoded).\n",
    "    metrics=[\n",
    "        keras.metrics.Accuracy(),\n",
    "        keras.metrics.Precision(),\n",
    "        keras.metrics.Recall(),\n",
    "        ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a04124",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_5layers_model_withDropout_WithoutRegularization = model_5layers_withDropout_WithoutRegularization.fit(x_train,y_train, epochs=20, validation_split=(1/20))\n",
    "history_5layers_model_withDropout_WithRegularization = model_5layers_withDropout_WithRegularization.fit(x_train,y_train, epochs=20, validation_split=(1/20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################################\n",
    "# Comparison of the training and validation accuracy of the three (4.1, 9.1 and 9.2)\n",
    "################################################################################################################################################\n",
    "plt.plot(history_5layers_model.history['accuracy'])\n",
    "plt.plot(history_5layers_model.history['val_accuracy'])\n",
    "plt.plot(history_5layers_model_withDropout_WithoutRegularization.history['accuracy'])\n",
    "plt.plot(history_5layers_model_withDropout_WithoutRegularization.history['val_accuracy'])\n",
    "plt.plot(history_5layers_model_withDropout_WithRegularization.history['accuracy'])\n",
    "plt.plot(history_5layers_model_withDropout_WithRegularization.history['val_accuracy'])\n",
    "plt.title('Training and Validation Accuracy History')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend([\n",
    "    '5-Layers (w/o Dropout, with L2 Regularization) Training Accuracy', '5-Layers Training (w/o Dropout, with L2 Regularization) Validation Accuracy', \n",
    "    '5-Layers (with Dropout, w/o Regularization) Training Accuracy', '5-Layers (with Dropout, w/o Regularization) Validation Accuracy', \n",
    "    '5-Layers (with Dropout, with L2 Regularization) Training Accuracy', '5-Layers (with Dropout, with L2 Regularization) Validation Accuracy', \n",
    "    ], \n",
    "    loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6529c4a9",
   "metadata": {},
   "source": [
    "# 10. Optimisers\n",
    "\n",
    "Modify the code written in section 5.2\n",
    "\n",
    "1. RMSProp with your choice of hyper parameters\n",
    "2. Adam with your choice of hyper parameters\n",
    "\n",
    "Plot the comparison of the training and validation accuracy of the three (5.2, 10.1 and 10.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf06eb1",
   "metadata": {
    "id": "9bf06eb1"
   },
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##\n",
    "model_5layers.compile(\n",
    "    optimizer=keras.optimizers.experimental.RMSprop(learning_rate=0.01),    # RMSProp optimizer, as mandated in section 10.1.\n",
    "    loss=keras.losses.CategoricalCrossentropy(),    # Categorical CE loss, as mandated above (also required because our target label is one-hot encoded).\n",
    "    metrics=[\n",
    "        keras.metrics.Accuracy(),\n",
    "        keras.metrics.Precision(),\n",
    "        keras.metrics.Recall(),\n",
    "        ],\n",
    ")\n",
    "history_5layers_model_RMSProp = model_5layers.fit(x_train,y_train, epochs=20, validation_split=(1/20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d36a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5layers.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.01),    # Adam optimizer, as mandated in section 10.2.\n",
    "    loss=keras.losses.CategoricalCrossentropy(),    # Categorical CE loss, as mandated above (also required because our target label is one-hot encoded).\n",
    "    metrics=[\n",
    "        keras.metrics.Accuracy(),\n",
    "        keras.metrics.Precision(),\n",
    "        keras.metrics.Recall(),\n",
    "        ],\n",
    ")\n",
    "history_5layers_model_Adam = model_5layers.fit(x_train,y_train, epochs=20, validation_split=(1/20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c7522aa",
   "metadata": {},
   "source": [
    "# 11. Conclusion\n",
    "\n",
    "Comparing the sections 4.1, 5.2, 8, 9, and 10, present your observations on which model or architecture or regualiser or optimiser perfomed better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc51130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##---------Type the code below this line------------------##"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
